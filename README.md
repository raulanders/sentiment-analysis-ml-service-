# ğŸ§  Sentiment Analysis ML Service (ES/PT)

Microservicio de anÃ¡lisis de sentimiento para espaÃ±ol y portuguÃ©s, desarrollado como componente de Data Science dentro de una arquitectura full-stack.

Este repositorio concentra mi contribuciÃ³n tÃ©cnica en:

- Pipeline ETL
- Modelado clÃ¡sico (TF-IDF + RegresiÃ³n LogÃ­stica)
- Fine-tuning de Transformer (RoBERTa)
- ImplementaciÃ³n de API con FastAPI
- DockerizaciÃ³n para despliegue reproducible

---

## ğŸ¯ Objetivo

Construir, comparar y desplegar modelos capaces de clasificar comentarios en:

- NEGATIVO  
- NEUTRO  
- POSITIVO  

Evaluando no solo desempeÃ±o (Accuracy, F1), sino tambiÃ©n robustez semÃ¡ntica y viabilidad de producciÃ³n.

---

# âš™ Arquitectura del Proyecto

El proyecto cubre el ciclo completo: `ETL â†’ Entrenamiento â†’ EvaluaciÃ³n â†’ Persistencia â†’ API â†’ Docker`


---

## ğŸ—‚ 1. ETL (ExtracciÃ³n y PreparaciÃ³n de Datos)

ImplementaciÃ³n de pipeline para:

- Limpieza y normalizaciÃ³n de texto
- EliminaciÃ³n de nulos y duplicados
- Etiquetado desde estrellas (1â€“2 negativo, 3 neutro, 4â€“5 positivo)
- Muestreo estratificado
- Consistencia entre datasets ES y PT

El objetivo fue generar datasets comparables y robustos para entrenamiento.

---

## ğŸ¤– 2. Modelado

### Baseline ClÃ¡sico â€“ TF-IDF + RegresiÃ³n LogÃ­stica

Resultados (PortuguÃ©s):

- Accuracy: **0.872**
- F1 Macro: **0.780**
- F1 Weighted: **0.871**

Ventajas:

- Bajo costo computacional
- Inferencia rÃ¡pida en CPU
- Alta escalabilidad

---

### Transformer â€“ RoBERTa (xlm-roberta-base)

Resultados:

- Accuracy: **0.857**
- F1 Macro: **0.835**
- F1 Weighted: **0.858**

Hallazgo clave:

Aunque el accuracy global fue ligeramente menor, RoBERTa mejorÃ³ el F1 Macro, mostrando mejor balance entre clases y mayor robustez contextual, especialmente en la clase NEUTRO.

---

# ğŸš€ 3. API â€“ FastAPI

ImplementÃ© un microservicio en FastAPI que:

- Carga modelos una sola vez al iniciar la aplicaciÃ³n
- Detecta automÃ¡ticamente el idioma (ES/PT)
- Enruta dinÃ¡micamente al modelo correspondiente
- Expone endpoints REST:

```
GET / â†’ Estado bÃ¡sico
GET /health â†’ Health check
POST /predict â†’ PredicciÃ³n de sentimiento
```

Incluye:

- ValidaciÃ³n de entrada con Pydantic
- Manejo controlado de errores HTTP
- Contrato consistente de salida (clase + probabilidad)
- Compatibilidad local y en contenedor Docker

---

# ğŸ³ 4. Docker

El servicio fue dockerizado para:

- Aislamiento de dependencias
- Entorno reproducible
- Portabilidad entre desarrollo y producciÃ³n
- IntegraciÃ³n sencilla con backend (Spring Boot)

---

# ğŸ“Š Enfoque de decisiÃ³n tÃ©cnica

Se realizÃ³ anÃ¡lisis costo-beneficio entre modelos clÃ¡sicos y Transformers considerando:

- DesempeÃ±o (Accuracy, F1)
- Robustez en clase NEUTRO
- Latencia
- Escalabilidad
- Costo computacional (CPU vs GPU)

DecisiÃ³n arquitectÃ³nica:

- RoBERTa como modelo principal cuando la prioridad es calidad.
- TF-IDF + RegresiÃ³n LogÃ­stica como fallback ligero y altamente escalable.

---

# ğŸ— Stack TecnolÃ³gico

- Python
- Pandas
- NumPy
- Scikit-learn
- Hugging Face Transformers
- PyTorch
- FastAPI
- Docker

---

# ğŸ“Œ Contexto

Este repositorio corresponde a mi contribuciÃ³n tÃ©cnica dentro de un proyecto full-stack desarrollado en equipo, donde fui responsable del pipeline de datos, modelado y despliegue del microservicio de inferencia.

